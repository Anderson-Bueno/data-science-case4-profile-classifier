üõ†Ô∏è Meios aplicados para chegar √† solu√ß√£o

No Case 4, resolvemos esse problema aplicando aprendizado supervisionado:

Constru√ß√£o da base de treino

Usamos os perfis gerados via clusteriza√ß√£o (Cases 1‚Äì3) como r√≥tulos (labels).

Features: RFMT (Rec√™ncia, Frequ√™ncia, Monet√°rio, Ticket), atributos derivados (mix de categorias, diversidade, concentra√ß√£o).

Modelagem supervisionada

Algoritmo: Random Forest Classifier (robusto a colinearidade, interpret√°vel, baseline forte).

Outras op√ß√µes poss√≠veis: Gradient Boosted Trees, XGBoost, LightGBM (fica como extens√£o futura).

Avalia√ß√£o de desempenho

M√©tricas:

Kappa de Cohen (consist√™ncia al√©m do acaso).

F1-Score Macro (equil√≠brio entre classes desbalanceadas).

Curva ROC-AUC (capacidade discriminativa).

Relat√≥rios autom√°ticos com classification_report.

Interpreta√ß√£o

Feature importance da Random Forest para explicar quais vari√°veis mais pesam na defini√ß√£o de perfis (ex: ticket m√©dio, frequ√™ncia, mix de categorias).

Visualiza√ß√µes (barplots, curvas ROC, matriz de confus√£o).

Produ√ß√£o e reuso

O modelo treinado pode ser salvo no MLflow (Databricks) ou GitHub (vers√£o open).

Novos clientes s√£o classificados diretamente sem passar pelo pipeline inteiro de clusteriza√ß√£o.
